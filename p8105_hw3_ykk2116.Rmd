---
title: "P8105_hw3_ykk2116"
author: "Yaa Klu"
date: "10/10/2018"
output: github_document
---

_Loading tidyverse_

```{r}
library(tidyverse)
library(ggthemes)
library(patchwork)
library(hexbin)
library(chron)
```

### Problem 1

_Loading BRFSS dataset_

```{r}
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

data(brfss_smart2010)
```

_Cleaning of dataset and selection of variables_

```{r}
brfss_df = janitor::clean_names(dat = brfss_smart2010) %>%
  filter(topic == "Overall Health") %>%
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>% 
  mutate(response = forcats::fct_relevel(response, c("Excellent", "Very good", "Good", "Fair", "Poor")))
```


_States that were observed at 7 locations_

```{r}
brfss_df %>%
  filter(year == 2002) %>%
  group_by(locationabbr) %>%
  distinct(locationdesc) %>%
  summarise(n = n()) %>%
  filter( n == 7) %>%
  knitr::kable()

```

_Spaghetti plot_ number of locations in each state

```{r}
brfss_df %>%
  distinct(locationabbr, locationdesc, year) %>% 
  group_by(locationabbr, year) %>%
  summarise(number_of_locations = n()) %>%
  ggplot(aes(x = year, y = number_of_locations, color = locationabbr)) +
  geom_line() +
labs(
  title = "Spaghetti Plot",
  x = "Year",
  y = "Number of Locations Observed",
  caption = "BRFSS 2010 Data"
)
scale_x_continuous(breaks = c(2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010))
```


_Making of Table_
```{r}
brfss_df %>%
  filter(year %in% c(2002, 2006, 2010)) %>%
  filter(locationabbr == "NY") %>%
  spread(key = response, value = data_value) %>% 
  janitor::clean_names(dat = .) %>% 
  group_by(locationabbr, year) %>%
  summarise(n = n(),
        mean = mean(excellent, na.rm = TRUE),
        sd = sd(excellent, na.rm = TRUE)) %>%
  knitr::kable()
```


```{r}
brfss_df %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names(dat = .) %>%
  group_by(locationabbr, year) %>%
  summarise( n = n(),
          mean_excellent = mean(excellent, na.rm = TRUE),
          mean_very_good = mean(very_good, na.rm = TRUE),
          mean_good = mean(good, na.rm = TRUE),
          mean_fair = mean(fair, na.rm = TRUE),
          mean_poor = mean(poor, na.rm = TRUE)) %>%
  gather(key = mean_variable, value = mean_value, mean_excellent:mean_poor) %>%
  ggplot(aes(x = year, y = mean_value, color = locationabbr)) +
  geom_line() +
  facet_grid(~mean_variable) 
```


### Problem 2

_Loading Dataset_

```{r}
data("instacart")
```

_Number of aisles and which aisles most items are ordered from_

```{r}
instacart %>%
  distinct(aisle_id) %>%
  count()

instacart %>%
  group_by(aisle_id, aisle) %>%
  summarise(number = n()) %>%
  ungroup() %>%
  top_n(5, number) %>%
  arrange(desc(number)) %>%
  knitr::kable()
```

_Plot that shows the number of items ordered in each aisle_

```{r}
instacart %>%
  group_by(aisle_id, aisle) %>%
  summarise(number = n()) %>%
  arrange(desc(number)) %>%
  mutate(asile = tools::toTitleCase(aisle)) %>%
  ggplot(aes(x = reorder(aisle, -number), y = number, fill = aisle)) +
  geom_col() +
  theme(axis.title.x = element_text(angle = 45, hjust = 1, size = 6),
        legend.position = "none") +
  labs(
    title = "Number of items ordered in each aisle",
    x = "Aisle",
    y = "Frequency of orders",
    caption = "Data from 2017 Instacart Online Grocery Shopping"
  )
```


_Table showing the most popular item in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”_

```{r}
instacart %>%
  select(aisle_id, aisle, product_id, product_name) %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>%
  summarise(number = n()) %>%
  top_n(1, number) %>%
  arrange(desc(number)) %>%
  knitr::kable()
```

_Table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week_

```{r}
instacart %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
group_by(order_dow, product_name) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  spread(key = order_dow, value = mean_hour) %>% 
  knitr::kable()
```


### Problem 3
_Loading dataset_

```{r}
data("ny_noaa")
```


```{r}
noaa_df = ny_noaa %>% 
  mutate(month = months.Date(date, abbreviate = TRUE),
         day = chron::days(date),
         year = chron::years(date),
         tmax = (as.numeric(tmax))/10,
         tmin = (as.numeric(tmin))/10,
         prcp = prcp/10)
```


```{r}
noaa_df %>% 
  group_by(snow) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number))
```




```{r}
noaa_df %>% 
  group_by(id, year, month) %>% 
  summarize(n = n(),
            sum = sum(tmax, na.rm = TRUE),
            mean = mean(tmax, na.rm = TRUE)) %>% 
  filter(month %in% c("Jan", "Jul")) %>% 
  ggplot(aes(x = year, y = mean, color = id)) +
  facet_grid(~month) + 
  geom_point() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 5)) +
  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE) 
```


_Average max temperature in January and in July in each station across years_

```{r}
noaa_df %>% 
  filter(month %in% c("Jan", "Jul")) %>% 
  ggplot(aes(x = year, y = tmax, color = year)) +
  facet_grid(~month) +
  geom_boxplot() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 5))
```

```{r}
my_hex = ggplot(noaa_df, aes(x = tmin, y = tmax)) +
  geom_hex(aes()) +
  theme(legend.position = "left")
        
my_boxes = noaa_df %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, y = snow, fill = year)) +
  geom_boxplot(alpha = 0.3) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 7))

my_hex / my_boxes
```





 