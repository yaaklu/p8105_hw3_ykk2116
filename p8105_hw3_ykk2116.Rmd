---
title: "P8105_hw3_ykk2116"
author: "Yaa Klu"
date: "10/10/2018"
output: github_document
---

_Loading tidyverse_

```{r}
library(tidyverse)
library(ggthemes)
library(patchwork)
library(hexbin)
library(chron)
```


### Problem 1


_Loading BRFSS dataset_

```{r}
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

data(brfss_smart2010)
```



_Cleaning of BRFSS dataset and selection of variables_

```{r}
brfss_df = janitor::clean_names(dat = brfss_smart2010) %>%
  filter(topic == "Overall Health") %>%
  mutate(response = forcats::fct_relevel(response, c("Excellent", "Very good", "Good", "Fair", "Poor")))
```



_States that were observed at 7 locations_

```{r}
brfss_df %>%
  filter(year == 2002) %>%
  group_by(locationabbr) %>%
  distinct(locationdesc) %>%
  summarise(n = n()) %>%
  filter( n == 7) %>%
  knitr::kable(digits = 2)

```

** According to the table above, in 2002, the states of CT, FL, NC were observed at 7 locations.**



_Spaghetti plot that shows the number of locations in each state from 2002 to 2010_

```{r}
brfss_df %>%
  distinct(locationabbr, locationdesc, year) %>% 
  group_by(locationabbr, year) %>%
  summarise(number_of_locations = n()) %>%
  ggplot(aes(x = year, y = number_of_locations, color = locationabbr)) +
  geom_line() +
scale_x_continuous(breaks = c(2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010)) +
labs(
  title = "Spaghetti Plot",
  x = "Year",
  y = "Number of Locations Observed",
  caption = "BRFSS 2010 Data"
)
```

**Looking at the plot above, we can see that majority of the states showed a similar trend in the number of locations across all the years. However, for one of the states, there was a huge spike or increase from 2006 to 2007 and it decreased again in 2008. However there was another increase from 2009 to 2010. The particular state is hard to identify as it is.**



_Table that shows the mean and standard deviation of the "excellent" responses across locations in NY state for 2002, 2006 and 2010_

```{r}
brfss_df %>%
  filter(year %in% c(2002, 2006, 2010)) %>%
  filter(locationabbr == "NY") %>%
  spread(key = response, value = data_value) %>% 
  janitor::clean_names(dat = .) %>% 
  group_by(locationabbr, year) %>%
  summarise(n = n(),
        mean = mean(excellent, na.rm = TRUE),
        sd = sd(excellent, na.rm = TRUE)) %>%
  knitr::kable(digits = 2)
```

**In the table above, we can see that the number of variables (N) increased through 2002 to 2010; from 25 in 2002, 30 in 2006 and to 45 in 2010. The mean in 2002 was different from the means in 2006 and 2010; the mean for 2006 and 2010 were similar. The standard deviation was highest in 2002 and it was lower in 2006 and lowest in 2010.**



_A five-panel violin plot that shows, for each response category separately, the distribution of state-level averages (average proportion in each response category) over time_

```{r}
average_brfss =
  brfss_df %>%
  group_by(locationabbr, year, response) %>%
  summarise(average = mean(data_value, na.rm = TRUE))


average_brfss %>%
  ggplot(aes(x = factor(year), y = average)) +
  geom_violin(aes(fill = factor(response))) +
  facet_grid(.~response) +
  stat_summary(fun.y = median, geom = "point", size = 0.5) +
  labs(
     title = "Distributon of state-level average proportion in each response category",
    x = "Year",
    y = "Average proportion in each response category",
    caption = "BRFSS 2010 Data"
  ) +
  scale_fill_discrete(name = "Response") +
  theme(axis.text.x = element_text(angle = 45, size = 6, hjust = 1))
```

**According to the violin plot above, overall, the average responses across the years increases in the following order across the type of response: POOR, FAIR, EXCELLENT, GOOD and VERY GOOD.**



### Problem 2

_Loading Instacart Dataset_

```{r}
data("instacart")
```


_Description of data_

**The instacart dataset has `r nrow(instacart)` observations and `r nrow(instacart)` variables. The variable order_id is a unique identifier of the orders made. The number of unique orders are `r nrow(distinct(instacart, order))`. There are `r nrow(distinct(instacart, user_id))` unique customers. The variables department_name, product_name, and aisle have  corresponding unique identifiers. The variable order_dow represents the day of the week orders were made and the order_hour_of_day represents the time or hour of day orders were made.** 


_Number of aisles and which aisles most items are ordered from_

```{r}
instacart %>%
  distinct(aisle_id) %>%
  count()

instacart %>%
  group_by(aisle_id, aisle) %>%
  summarise(number = n()) %>%
  ungroup() %>%
  top_n(10, number) %>%
  arrange(desc(number)) %>%
  knitr::kable(digits = 2)
```

**From the output above, there are `r pull(count(distinct(instacart, aisle_id)))` aisles. Also, the output shows the top ten most popular aisles, with the top being fresh vegetables aisles.**




_Bar plot that shows the number of items ordered in each aisle_

```{r barplot, fig.height=20}
instacart %>%
  group_by(aisle_id, aisle) %>%
  summarise(number = n()) %>%
  arrange(desc(number)) %>%
  mutate(asile = tools::toTitleCase(aisle)) %>%
  ggplot(aes(x = reorder(aisle, -number), y = number, fill = aisle)) +
  geom_col() +
  theme(axis.title.x = element_text(angle = 45, hjust = 1, size = 6),
        legend.position = "none") +
  labs(
    title = "Number of items ordered in each aisle",
    x = "Aisle",
    y = "Frequency of orders",
    caption = "Data from 2017 Instacart Online Grocery Shopping"
  ) +
coord_flip()
```

**The barplot shows the number of times ordered in each aisle and the highest number of items corresponds to the what was previosuly observed as the 10 most popular aisles.**


_Table showing the most popular item in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”_

```{r}
instacart %>%
  select(aisle_id, aisle, product_id, product_name) %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>%
  summarise(number = n()) %>%
  top_n(1, number) %>%
  arrange(desc(number)) %>%
  knitr::kable(digits = 2)
```

**From the table above, the most popular item in the "packaged vegetables fruits" is Organic Baby Spinach", that for "Baking Ingredients" is Light Brown Sugar and that for "dog food care" is Snack Sticks Chicken & Rice Recipe Dog Treats**


_Table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week_

```{r}
instacart %>%
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>%
group_by(order_dow, product_name) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  spread(key = order_dow, value = mean_hour) %>% 
  knitr::kable(digits = 2)
```

**From the output above, for the 1st and 6th day of the week, the mean hour of the day for which the 2 products are ordered are similar. However for the rest of the week, the mean hour is later for Coffee Ice Cream, meaning people order the ice-cream at a much later time in the day.**



### Problem 3

_Loading nynoaa dataset_

```{r}
data("ny_noaa")
```

_Data cleaning_

```{r}
noaa_df = ny_noaa %>% 
  mutate(month = months.Date(date, abbreviate = TRUE),
         day = chron::days(date),
         year = chron::years(date),
         tmax = (as.numeric(tmax))/10,
         tmin = (as.numeric(tmin))/10,
         prcp = prcp/10)
```

_Short description of data_

**The dataset has `r nrow(noaa_df)` observations and `r ncol(noaa_df)` variables. The dataset also contains `r nrow(distinct(noaa_df, id))` unique stations that recorded weather information from the years 1981 to 2010. There are variables that also has information on precipitation (prcp), maximum and minimum temperature (tmax and tmin) and snow fall(snow) and snow depth (snwd).** 


```{r}
noaa_df %>% 
  group_by(snow) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number))
```

**For snowfall, the most commonly observed values are 0 and NA. This is probably due to the fact that most days of the year there is no snowfall. Additionally, there might have been stations that may not have any records of snow due to technical difficulties in recording or perhaps they do not record any snowfall even if there are snow days.**

_A two-panel plot showing the average max temperature in January and in July in each station across years_

```{r}
noaa_df %>% 
  group_by(id, year, month) %>% 
  summarize(n = n(),
            sum = sum(tmax, na.rm = TRUE),
            mean = mean(tmax, na.rm = TRUE)) %>% 
  filter(month %in% c("Jan", "Jul")) %>% 
  ggplot(aes(x = year, y = mean, color = month)) +
  facet_grid(~month) + 
  geom_point() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 5)) +
  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE) 
```

**Looking at the plot above, generally the average temperatures were higher in July, compared to January, although there were some very few outliers recorded.**

_Average max temperature in January and in July in each station across years_

```{r}
noaa_df %>% 
  filter(month %in% c("Jan", "Jul")) %>% 
  ggplot(aes(x = year, y = tmax, color = month)) +
  facet_grid(~month) +
  geom_boxplot() +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 5))
```





```{r}
my_hex = ggplot(noaa_df, aes(x = tmin, y = tmax)) +
  geom_hex(aes()) +
  theme(legend.position = "left")
        
my_boxes = noaa_df %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, y = snow, fill = year)) +
  geom_boxplot(alpha = 0.3) +
  theme(legend.position = "none", 
        axis.text.x = element_text(angle = 45, hjust = 1, size = 7))

my_hex / my_boxes
```





 